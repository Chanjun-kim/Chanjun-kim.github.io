---
layout: post
title: "앙상블(Ensemble) 모델"
author: "Chanjun Kim"
categories: Data분석
tags: [Ensemble, 앙상블, Bagging, Boosting, Bootstrap, xgboost, catboost, adaboost, lightgbm, modeling]
image: 02_ensemble.jpg
---

## **목적**
- 지금까지 랜덤포레스트, xgboost, 딥러닝 등의 모델을 활용하고 비교할 때 단지 rmse 등의 metric을 통한 성능으로 모델을 결정하였다. 이에 대하여 앙상블 모델에 대하여 완벽하진 않지만 개념적으로 이해를 하는 것이 좋다고 판단되었다.
<br/>

---

<br/>

## **앙상블 모델이란?**
하나의 모델을 통한 결과가 아닌 **다수의 모델**을 활용하여 결과를 향상시키도록 하는 학습 모델
- *다수의 약한 모형(Weak learner, ex. 의사결정 나무)를 종합하여 강한 모형(String learner)를 만드는 것이 목적이다.*
- 정확도가 높아지면서 해석의 모호함이 생길 수 있습니다.<br/>
![Oops](https://www.kdnuggets.com/wp-content/uploads/explainable_boosting_machine_01.jpg)
> 출처 : https://www.kdnuggets.com/2021/05/explainable-boosting-machine.html <br/>

위의 그림과 같이 앙상블 모델의 종류인 Gradient Boosting과 Random Forest는 Decision Tree, 선형회귀보다는 높은 정확도를 가지나, 해석력에 있어서 불리하다는 단점을 가지고 있습니다.

<br/>

## **앙상블 모델의 종류**
1. **Voting** : 여러개의 모델의 결과를 토대로 다수의 분류기가 예측한 값 혹은 평균 등을 최종 결과로 선정하는 앙상블 모형
2. **Bagging** : Bootstrap Aggregation의 약자로, 동일한 알고리즘으로 여러개의 약한 모형를 Boot Strapping된 샘플 데이터를 학습시켜 예측하는 앙상블 모형 ([참고](https://injo.tistory.com/30))
3. **Boosting** : 
4. **Stacking**

---
## **1. Voting**
여러개의 모델의 결과를 토대로 다수의 분류기가 예측한 값 혹은 평균 등을 최종 결과로 선정하는 앙상블 모형([참고](https://libertegrace.tistory.com/entry/Classification-2-%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5Ensemble-Learning-Voting%EA%B3%BC-Bagging))

- **Hard Voting**
    - 각 분류기의 결과를 바탕으로 다수의 결과를 최종 결과로 나타냄.
- **Soft Voting**
    - 각 분류기의 결과의 확률을 평균으로하여 최종 결과로 나타냄(일반적으로 사용됨.)
- Regression 모델의 경우 자동으로 평균을 나타냄.(잘 사용하지 않음)

![Oops](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcvYig2%2FbtqKsojGyfl%2FiKazMxfc8GKeWa1OHYjHH0%2Fimg.png)
> 출처 : https://libertegrace.tistory.com/entry/Classification-2-%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5Ensemble-Learning-Voting%EA%B3%BC-Bagging

<br/>
<br/>

- ~~Voting 방법은 결국 개별 분류기 중 가장 뛰어난 것을 넘기 힘들 것 같지만, 의외로 정확도가 높은 경우가 많다고 합니다.(핸즈온 머신러닝 중)~~<br/>
- <u>*또한 앙상블 모형은 모델이 서로 가능한한 독립적일 때 서로 다른 오차를 만들어 최고의 성능을 발휘한다고 합니다.(핸즈온 머신러닝 중)*</u><br/>

<br/>

---
## **2. Bagging**
Bootstrap Aggregation의 약자로, 동일한 알고리즘으로 여러개의 약한 모형를 Bootstrapping으로 샘플링된 데이터를 학습시켜 예측하는 앙상블 모형
<br/>

- ### **약한 모형이란?**
    - 랜덤 추출보다 예측력이 좋으나 연산이 빠른 모델(ex. Decision Tree)
    
- ### **Bootstrap이란?**
    - 복원 추출이 가능한 Random Sampling 기법
    - 복원 추출이 가능하기 때문에 아래의 그림과 같이 각 샘플에서 표본보다 많은 Y값(색깔공)이 보일 수 있습니다. <br/> ![Oops](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Ensemble_Bagging.svg/1920px-Ensemble_Bagging.svg.png)
    > 출처 : https://en.wikipedia.org/wiki/Bootstrap_aggregating
    - 











---
<br/>

참고 자료 : 
[https://bkshin.tistory.com/entry/](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-11-%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5-Ensemble-Learning-%EB%B0%B0%EA%B9%85Bagging%EA%B3%BC-%EB%B6%80%EC%8A%A4%ED%8C%85Boosting)