{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCQ4MIS2mv4N"
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: \"Auto Encoder란 무엇일까?\"\n",
    "author: \"Chanjun Kim\"\n",
    "categories: Data분석\n",
    "tags: [Data, AutoEncoder, AE, Gan, Denoising AE, VAE, 딥러닝, CNN]\n",
    "image: 08_AutoEncoder.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66ofBhh4mv4Q"
   },
   "source": [
    "## **학습목적**\n",
    "이 포스팅에선 GAN을 배우기 전 이미지를 생성하는 오토인코더에 대해서 알아보도록 하겠습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vsMVZXjmv4R"
   },
   "source": [
    "#### **오토인코더란?**\n",
    "- 오토인코더(Autoencoder)의 기본적인 개념은 저차원(직관적)인 데이터를 고차원(추상적)의 데이터로 표현(representation)하고 다시 저차원의 데이터로 만들어 데이터 생성, 노이즈 제거, 특성 변화 등을 할 수 있도록 만들어주는 기법으로, 오토 인코더라고 불리지만 실제로는 인코더와 디코더가 같이 묶여있는 네트워크이다.\n",
    "    - 저차원과 고차원\n",
    "        - 인코더는 차원 축소라고 표현되나, 잠재공간(Latent Space)가 늘어나며 추상적인 고차원 데이터로 변환된다.\n",
    "        - 128x128x3의 이미지는 사람의 눈으로도 판단 가능한 직관적인 데이터지만 2x2x32 같이 잠재공간(Latent Space)가 많은 경우는 사람의 눈으로는 판단할 수 없는 추상적인 데이터라고 볼 수 있다.\n",
    "\n",
    "<br>\n",
    "\n",
    "![Oops](data:image/png;base64,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)\n",
    "\n",
    "> 출처: https://excelsior-cjh.tistory.com/187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzsUdxzGwoM1"
   },
   "source": [
    "---\n",
    "\n",
    "#### **오토인코더 실습**\n",
    "- 단순한 데이터셋(mnist 등)를 통하여 잠재 공간에 어떻게 표현되는 지 확인하고 고차원의 데이터를 실습한 후 AE의 한계점을 이해하고 이것을 해결한 VAE까지 소개하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1627201469866,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "CC3TPDHjwuln",
    "outputId": "0e9c7322-dd4a-41c5-e2f4-7747b36592bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "[Errno 2] No such file or directory: 'drive/MyDrive/cj/portfolio/Chanjun-kim.github.io/_ipynb'\n",
      "/content/drive/MyDrive/cj/portfolio/edu/시각인지/실습\n",
      "/content/drive/My Drive/cj/portfolio/edu/시각인지/실습\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "%cd drive/MyDrive/cj/portfolio/Chanjun-kim.github.io/_ipynb\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 5334,
     "status": "ok",
     "timestamp": 1627201564038,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "p2MtC3_DwoM5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import * \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1627201602298,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "tUmVU1IKwoM6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1627202585918,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "4-XQLwBTwoM_"
   },
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , encoder_conv_filters\n",
    "        , encoder_conv_kernel_size\n",
    "        , encoder_conv_strides\n",
    "        , decoder_conv_t_filters\n",
    "        , decoder_conv_t_kernel_size\n",
    "        , decoder_conv_t_strides\n",
    "        , z_dim\n",
    "        , use_batch_norm = False\n",
    "        , use_dropout = False\n",
    "        ):\n",
    "\n",
    "        self.name = 'autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "\n",
    "        ### THE ENCODER\n",
    "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
    "\n",
    "        x = encoder_input\n",
    "\n",
    "        for i in range(self.n_layers_encoder):\n",
    "            conv_layer = Conv2D(\n",
    "                filters = self.encoder_conv_filters[i]\n",
    "                , kernel_size = self.encoder_conv_kernel_size[i]\n",
    "                , strides = self.encoder_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'encoder_conv_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_layer(x)\n",
    "\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate = 0.25)(x)\n",
    "\n",
    "        shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        encoder_output= Dense(self.z_dim, name='encoder_output')(x)\n",
    "\n",
    "        self.encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "\n",
    "        ### THE DECODER\n",
    "        decoder_input = Input(shape=(self.z_dim,), name='decoder_input')\n",
    "\n",
    "        x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "        x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "        for i in range(self.n_layers_decoder):\n",
    "            conv_t_layer = Conv2DTranspose(\n",
    "                filters = self.decoder_conv_t_filters[i]\n",
    "                , kernel_size = self.decoder_conv_t_kernel_size[i]\n",
    "                , strides = self.decoder_conv_t_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'decoder_conv_t_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_t_layer(x)\n",
    "\n",
    "            if i < self.n_layers_decoder - 1:\n",
    "                x = LeakyReLU()(x)\n",
    "                \n",
    "                if self.use_batch_norm:\n",
    "                    x = BatchNormalization()(x)\n",
    "                \n",
    "                if self.use_dropout:\n",
    "                    x = Dropout(rate = 0.25)(x)\n",
    "            else:\n",
    "                x = Activation('sigmoid')(x)\n",
    "\n",
    "        decoder_output = x\n",
    "\n",
    "        self.decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "        ### THE FULL AUTOENCODER\n",
    "        model_input = encoder_input\n",
    "        model_output = self.decoder(encoder_output)\n",
    "\n",
    "        self.model = Model(model_input, model_output)\n",
    "        \n",
    "    def compile(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "        def r_loss(y_true, y_pred):\n",
    "            return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "\n",
    "        self.model.compile(optimizer=optimizer, loss = r_loss) \n",
    "\n",
    "    def train(self, x_train, batch_size, epochs):\n",
    "        self.model.fit(     \n",
    "          x_train\n",
    "          , x_train\n",
    "          , batch_size = batch_size\n",
    "          , shuffle = True\n",
    "          , epochs = epochs\n",
    "        )               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRlMwMMQwoNA"
   },
   "source": [
    "> 출처 : https://github.com/davidADSP/GDL_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsDyaX62woNB"
   },
   "source": [
    "1. 최초의 데이터를 28 x 28 데이터를 인풋으로 받습니다.\n",
    "2. Encoder와 Decoder의 깊이는 len(encoder_conv_filters), len(decoder_conv_t_filters)로 정해지므로 각각 4개의 Convolution 층을 갖게 됩니다.\n",
    "   - Convolution Filter의 차원은 1(Grey Scale Input) - (32 - 64 - 64 -64, Encoder Convolution Filter) - 2(represention) - (64 - 64 - 32, Decoder Convolution Filter) - 1(Grey Scale Output) 으로 구성됩니다.\n",
    "3. Encoder와 Decoder 모두 Activation Function은 LeakyRelu를 활용합니다.\n",
    "4. kernel size는 3x3으로 진행됩니다.\n",
    "5. stride를 2로 주어 차원 1/2로 축소합니다.\n",
    "6. encoder의 최종 차원을 2차원으로 만들어 잠재공간에 어떻게 분포되는지 확인하겠습니다.\n",
    "7. loss function은 MSE를 사용하고 최종 Activation function은 Sigmoid를 사용합니다.\n",
    "8. Optimizer는 Adam을 활용합니다.\n",
    "9. Auto Encoder 같은 경우는 Input과 Output이 같습니다. 그렇기 때문에 마지막 fit 부분에 x = x_train, y = x_train으로 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1627202588857,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "Bj0MAjSkwoNB"
   },
   "outputs": [],
   "source": [
    "AE = Autoencoder(\n",
    "    input_dim = (28,28,1)\n",
    "    , encoder_conv_filters = [32,64,64,64]\n",
    "    , encoder_conv_kernel_size = [3,3,3,3]\n",
    "    , encoder_conv_strides = [1,2,2,1]\n",
    "    , decoder_conv_t_filters = [64,64,32,1]\n",
    "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "    , decoder_conv_t_strides = [1,2,2,1]\n",
    "    , z_dim = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1627202592633,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "2djelibRwoNC"
   },
   "outputs": [],
   "source": [
    "AE.compile(0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1627202593215,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "z34e0t5kwoND",
    "outputId": "7a8e35dc-5373-4d7f-db3d-4e69e04b41d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_112 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_113 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_114 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 6274      \n",
      "=================================================================\n",
      "Total params: 98,946\n",
      "Trainable params: 98,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AE.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1627202594288,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "tDWGmfM7woNE",
    "outputId": "42b78ccb-6dde-4b57-f2a2-487d90315d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_116 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_117 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_118 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AE.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1101,
     "status": "ok",
     "timestamp": 1627201642772,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "g2Blw2ldwoM8",
    "outputId": "c453beca-057d-4ff3-8d82-7c7299f4e4ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1627201896572,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "L8VuJVZ7woM-",
    "outputId": "970137b6-32fb-4e9d-b8b3-583850fcfac4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(y_train[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1627201897101,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "fY-Joe-owoNF"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1627202768277,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "0rmAESzr173B"
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1627202862024,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "wLtyU-Xq2RoJ",
    "outputId": "68f76558-32bc-4017-98a8-7912f2febcf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "error",
     "timestamp": 1627203045117,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "mj976gRJwoNE",
    "outputId": "d66282e2-76f4-4e58-bb4b-1e6fa36423a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 114/1875 [>.............................] - ETA: 1:28 - loss: 0.2169"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-6f2b4c3b3a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-8543fbc0efff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         self.model.fit(     \n\u001b[0m\u001b[1;32m    118\u001b[0m           \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m           \u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AE.train(x_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y59yFR0ywoM7"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaGZ7A6hwoNF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021-07-25-AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
