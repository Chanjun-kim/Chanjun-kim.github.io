{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ad059b-f9d1-460a-a359-45b5fc7f2e4a",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: \"Loss function이란 무엇일까?\"\n",
    "author: \"Chanjun Kim\"\n",
    "categories: Data분석\n",
    "tags: [Data, Lossfunction, 손실함수, 목적함수, 비용함수, 머신러닝, 딥러닝, ML, DeepLearning]\n",
    "image: 06_LSTM.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0614d-5955-4e3e-b794-ebff9cead3b2",
   "metadata": {},
   "source": [
    "## **학습목적**\n",
    "이 포스팅에선 머신러닝/딥러닝에 쓰이는 Loss function에 대해서 알아보겠습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc0cf9-83c9-4a1e-ae5b-06ebe77d8670",
   "metadata": {},
   "source": [
    "#### **1. Objective / Cost / Loss function**\n",
    "- 만들고자 하는 머신러닝/딥러닝 모델을 만들 때 대체로 Loss function이란 말을 쓰지만 조금의 차이가 있을 수 있으니 위 세개의 말이 어떻게 다른지 알아보겠습니다.\n",
    "\n",
    "**1. Objective Function(목적 함수)**\n",
    "- 목적함수는 셋 중에 가장 큰 범위로 말 그대로 모델을 만드는 목적을 말합니다. 보통 Loss function은 오차를 최소화하기 위한 것이지만 MLE 같이 최대화하는 경우는 Loss function에는 포함되지 않습니다.\n",
    "\n",
    "**2. Loss Function(손실 함수)**\n",
    "- 손실 함수는 우리가 가지고 있는 예측된 값과 실제 Y값의 차이를 계산하는 함수입니다.\n",
    "\n",
    "**3. Cost Function(목적 함수)**\n",
    "- 목적함수는 전체 데이터의 손실의 합을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53173fd7-32c4-47e8-914d-7335a39ca969",
   "metadata": {},
   "source": [
    "### **모델 종류에 따른 Cost function의 종류**\n",
    "- 분류 모델인지 회귀 모델인지에 따라서 각각 다른 Cost/Loss function을 사용하고 그 안에서도 다양하게 분류되어있습니다.\n",
    "    - 이 중에서 대표적인 함수 몇개에 대해서 알아보도록 하겠습니다.\n",
    "\n",
    "![Oops](https://miro.medium.com/max/972/1*3MsFzl7zRZE3TihIC9JmaQ.png)\n",
    "\n",
    "- *사실 Loss function과 Cost function이 혼용되어 사용되고 있는 것 같습니다.*\n",
    "    \n",
    "> 출처 : [https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0](https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db49ee9-bdc2-442c-b94d-80826c1e1a4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 1. MSE - Mean Squared Error(평균 제곱 오차)\n",
    "\n",
    "![Oops](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FraTNF%2FbtqILMEZ4dR%2FGVFcXNBaX3KXuGWJ2MHsTk%2Fimg.png)\n",
    "\n",
    "- 실제값과 예측값 오차(Error)의 제곱값의 평균입니다. \n",
    "    - 즉 오차의 제곱이 Loss function, 그 평균이 Cost function이 됩니다.(이 설명은 아래서부터는 생략하겠습니다.)\n",
    "    - Gradient Descent를 할 때 미분값이 활용되므로 가장 일반적인 비용함수로 활용된다고 합니다.\n",
    "    - 사용되지만 Error에 제곱을 하기 때문에 이상치에 민감하게 되는 특성을 가지고 있습니다.\n",
    "    \n",
    "---\n",
    "    \n",
    "##### 1.1 RMSE - Root Mean Squared Error(평균 절대 오차)\n",
    "\n",
    "![Oops](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F8rc53%2FbtqIOoQ7txw%2FNYjEa95VQGXdJKAkK15tn0%2Fimg.png)\n",
    "\n",
    "- 실제값과 예측값 오차(Error)의 제곱값의 평균의 제곱근 값입니다. \n",
    "    - MSE가 실제 값에 제곱이 되어있기 때문에 평가지표로서 비교하기 어려움으로 제곱근을 하면 비교가 용이해집니다.(표준편차와 분산 이라고 생각하시면 될 것 같습니다.)\n",
    "    - Gradient Descent를 할 때 미분값이 활용되므로 가장 일반적인 비용함수로 활용된다고 합니다.\n",
    "    - 사용되지만 Error에 제곱을 하기 때문에 이상치에 민감하게 되는 특성을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad009e-b3a0-4c90-bfca-81478dc53caa",
   "metadata": {},
   "source": [
    "#### 2. MAE - Mean Absolute Error(평균 절대 오차)\n",
    "\n",
    "![Oops](https://blog.kakaocdn.net/dn/p0MT3/btqIPQ7GhmP/yk484qPJ3MK90RG9gnFOR1/img.png)\n",
    "\n",
    "- 실제값과 예측값 오차(Error)의 절대값의 평균입니다.\n",
    "    - 실제 값에 절대값만 취했기 때문에 오차에 민감하지 않습니다.\n",
    "    - 미분을 하면 항상 일정하기 때문에 수렴이 안될 수도 있습니다.\n",
    "    - 보통 Cost function보다는 평가지표로서 쓰이는 경우가 많습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462aef0-7356-4d3f-90de-6154ef147ff4",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e07788-38d3-46d9-b0f9-10dd5d55122f",
   "metadata": {},
   "source": [
    "> 출처 : [https://brunch.co.kr/@tristanmhhd/14](https://brunch.co.kr/@tristanmhhd/14)<br>\n",
    "> 출처 : [https://steadiness-193.tistory.com/277]](https://steadiness-193.tistory.com/277)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05592812-dd89-47c2-9bb2-85e19b7b4d2c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "code : https://github.com/Chanjun-kim/Chanjun-kim.github.io/blob/main/_ipynb/2021-07-05-LossFunction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da81da-d77f-4552-bc93-131fdc63acce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "참고 자료 : \n",
    "- https://ganghee-lee.tistory.com/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5825e934-0328-4fce-8f95-addf0f8ec753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf78ae-cf80-40e3-ae22-c7a0d6d5447d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
