{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCQ4MIS2mv4N"
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: \"AE3. Denoising AE - 노이즈제거 오토인코더란?\"\n",
    "author: \"Chanjun Kim\"\n",
    "categories: Data분석\n",
    "tags: [Data, AutoEncoder, AE, Gan, Denoising AE, VAE, 딥러닝, CNN]\n",
    "image: 08_AutoEncoder.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66ofBhh4mv4Q"
   },
   "source": [
    "## **학습목적**\n",
    "이 포스팅에선 저번 포스팅에서 알아본 오터인코더의 단점을 보완한 변이형 오토인코더에 대해서 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGJTcUcZdOnt"
   },
   "source": [
    "---\n",
    "\n",
    "#### **Denosing AutoEncoder - **\n",
    "- 오토인코더(Autoencoder)의 기본적인 개념은 저차원(직관적)인 데이터를 고차원(추상적)의 데이터로 표현(representation)하고 다시 저차원의 데이터로 만들어 데이터 생성, 노이즈 제거, 특성 변화 등을 할 수 있도록 만들어주는 기법으로, 오토 인코더라고 불리지만 실제로는 인코더와 디코더가 같이 묶여있는 네트워크입니다.\n",
    "    - 저차원과 고차원\n",
    "        - 인코더는 차원 축소라고 표현되나, 잠재공간(Latent Space)가 늘어나며 추상적인 고차원 데이터로 변환됩니다..\n",
    "        - 128x128x3의 이미지는 사람의 눈으로도 판단 가능한 직관적인 데이터지만 2x2x32 같이 잠재공간(Latent Space)가 많은 경우는 사람의 눈으로는 판단할 수 없는 추상적인 데이터라고 볼 수 있습니다.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzsUdxzGwoM1"
   },
   "source": [
    "---\n",
    "\n",
    "#### **오토인코더 실습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112543,
     "status": "ok",
     "timestamp": 1627296351922,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "CC3TPDHjwuln",
    "outputId": "2bfb02a8-b34a-4e44-d058-b4138ed9f729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/cj/portfolio/Chanjun-kim.github.io/_ipynb\n",
      "/content/drive/MyDrive/cj/portfolio/Chanjun-kim.github.io/_ipynb\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "%cd drive/MyDrive/cj/portfolio/Chanjun-kim.github.io/_ipynb\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3222,
     "status": "ok",
     "timestamp": 1627296371592,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "p2MtC3_DwoM5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import * \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1627296371593,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "tUmVU1IKwoM6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1627296406192,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "WX0yd70UdOnu"
   },
   "outputs": [],
   "source": [
    "class Denoising_Autoencoder_V1():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , encoder_conv_filters\n",
    "        , encoder_conv_kernel_size\n",
    "        , encoder_conv_strides\n",
    "        , decoder_conv_t_filters\n",
    "        , decoder_conv_t_kernel_size\n",
    "        , decoder_conv_t_strides\n",
    "        , z_dim\n",
    "        , use_batch_norm = False\n",
    "        , use_dropout = False\n",
    "        ):\n",
    "\n",
    "        self.name = 'autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "\n",
    "        ### THE ENCODER\n",
    "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
    "\n",
    "        x = encoder_input\n",
    "\n",
    "        for i in range(self.n_layers_encoder):\n",
    "            conv_layer = Conv2D(\n",
    "                filters = self.encoder_conv_filters[i]\n",
    "                , kernel_size = self.encoder_conv_kernel_size[i]\n",
    "                , strides = self.encoder_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'encoder_conv_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_layer(x)\n",
    "\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate = 0.25)(x)\n",
    "\n",
    "        shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        encoder_output= Dense(self.z_dim, name='encoder_output')(x)\n",
    "\n",
    "        self.encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "\n",
    "        ### THE DECODER\n",
    "        decoder_input = Input(shape=(self.z_dim,), name='decoder_input')\n",
    "\n",
    "        x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "        x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "        for i in range(self.n_layers_decoder):\n",
    "            conv_t_layer = Conv2DTranspose(\n",
    "                filters = self.decoder_conv_t_filters[i]\n",
    "                , kernel_size = self.decoder_conv_t_kernel_size[i]\n",
    "                , strides = self.decoder_conv_t_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'decoder_conv_t_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_t_layer(x)\n",
    "\n",
    "            if i < self.n_layers_decoder - 1:\n",
    "                x = LeakyReLU()(x)\n",
    "                \n",
    "                if self.use_batch_norm:\n",
    "                    x = BatchNormalization()(x)\n",
    "                \n",
    "                if self.use_dropout:\n",
    "                    x = Dropout(rate = 0.25)(x)\n",
    "            else:\n",
    "                x = Activation('sigmoid')(x)\n",
    "\n",
    "        decoder_output = x\n",
    "\n",
    "        self.decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "        ### THE FULL AUTOENCODER\n",
    "        model_input = encoder_input\n",
    "        model_output = self.decoder(encoder_output)\n",
    "\n",
    "        self.model = Model(model_input, model_output)\n",
    "        \n",
    "    def compile(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "        self.model.compile(optimizer=optimizer, loss = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")) \n",
    "\n",
    "    def train(self, x_train, y_train, batch_size, epochs, verbose = 1):\n",
    "        self.model.fit(     \n",
    "        x_train\n",
    "        , y_train\n",
    "        , batch_size = batch_size\n",
    "        , shuffle = True\n",
    "        , epochs = epochs\n",
    "        , verbose = verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1627296413955,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "XS04oM8lnF6s"
   },
   "outputs": [],
   "source": [
    "DAE_V1.compile(0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 1931,
     "status": "ok",
     "timestamp": 1627297369551,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "9piN_wAneB2J",
    "outputId": "1eb50afb-949e-4763-93d0-2f06510cc605"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAACACAYAAACx+5SIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2da6xd1bXfx0rgEmKeDg+DjR/YmDfYJpg3JWASCGpykyakSnpTKVJatUq/9KH2QypVt1dqv90P1dWtIiW5aVNVCREtNIUGCOFl3mCwjW3AgI3xCxzMM4SEZPXDwTP/+fdZk7X32efstff5/SSkcbzWXnvuNdcYa67F+I9R1XUdAAAAAAAAAADQLT427AEAAAAAAAAAAMDB8NIGAAAAAAAAAKCD8NIGAAAAAAAAAKCD8NIGAAAAAAAAAKCD8NIGAAAAAAAAAKCD8NIGAAAAAAAAAKCD8NIGAAAAAAAAAKCDjPVLm6qq3rH//lBV1X8Z9rigN6qqOqyqqu9XVbW9qqq3q6p6qqqq64c9LmhPVVXfqarq8aqq3q+q6u+GPR7oj6qq5lZV9b+qqnr3Q3/8+rDHBP1TVdVpVVX9tqqqHw97LNAbxNTxAl8cXaqqOrOqqrurqnqzqqqtVVV9adhjgt6pquqeD33wwDPjs8MeE/TGuPviWL+0qev6iAP/RcS8iHgvIm4a8rCgdw6JiB0R8fci4uiI+G5E/LSqqsVDHBP0xq6I+KuI+MGwBwJT4m8i4ncRcWJEfCMi/raqqrOHOySYAn8TEY8NexDQF8TU8QJfHEGqqjokIm6JiJ9HxNyI+CcR8eOqqpYPdWDQL9+RZ8fThz0YaM9s8MWxfmlj/IOIeDUi7h/2QKA36rp+t67r/1DX9ba6rv9Y1/XPI+KliLhg2GODdtR1fXNd1/87In497LFAf1RVNScm4ui/r+v6nbquH4iIWyPiL4Y7MuiHqqr+YUS8ERG/HPZYoHeIqeMDvjjSnBERJ0fEX9d1/Ye6ru+OiLXBfRFgphl7X5xNL23+cUT8t7qu62EPBKZGVVUnRsTyiHhm2GMBmEUsj4gP6rp+Tv7t6Ygg02bEqKrqqIj4y4j4l8MeC8BsBl8cS6qIOGfYg4C++E9VVe2rqmptVVVXDXswMGXGyhdnxUubqqoWxYS05kfDHgtMjaqqDo2I/xERP6rresuwxwMwizgiIt6yf3szIo4cwlhgavzHiPh+XdevDHsgALMcfHG0eTYmsvj/TVVVh1ZV9dmYeN745HCHBX3wbyPi1IiYHxHfi4j/U1XV0uEOCXpg7H1xVry0iYnUqAfqun5p2AOB/qmq6mMR8d9joqbGd4Y8HIDZxjsRcZT921ER8fYQxgJ9UlXViohYExF/PeyxAMxm8MXRp67r30fEn0fEDRGxJyL+VUT8NCJ4CTdi1HX9SF3Xb9d1/X5d1z+KCWnN54c9LmjHbPDFQ4Y9gBnimxHxn4c9COifqqqqiPh+TBRA/fyHzgkAM8dzEXFIVVWn1XX9/If/dn4gUxw1roqIxRHx8kRYjSMi4uNVVZ1V1/WqIY4LYLZxVeCLI09d1+tj4v/oR0REVVUPBpn940AdE/IaGBHG3RfHPtOmqqpLYyLVja5Ro83fRsSZEfH367p+b9iDgd6oquqQqqo+EREfj4lF6Sc+rPQOI0Jd1+9GxM0R8ZdVVc2pquqyiPhiTGS/wejwvYhYGhErPvzvv0bE/42Izw1zUNAbxNSxAF8cA6qqOu9D//tkVVX/OiJOioi/G/KwoAeqqjqmqqrPHYijVVV9IyKujIj/N+yxQXvG3RfH/qVNTBQgvrmua1L4R5QPaxL905hY1OypquqdD//7xpCHBu35bkS8FxH/LiL+0Yf2d4c6IuiHfx4Rh8eEbvh/RsQ/q+uaTJsRoq7r39R1vefAfzEhe/ttXdevDXts0BPE1BEHXxwb/iIidsfEffGaiLi2ruv3hzsk6JFDI+KvIuK1iNgXEf8iIv7cGi9A9xlrX6xopgQAAAAAAAAA0D1mQ6YNAAAAAAAAAMDIwUsbAAAAAAAAAIAOwksbAAAAAAAAAIAOwksbAAAAAAAAAIAOwksbAAAAAAAAAIAOckgvO1dVRaupIVHXdTWI4zCHOVX1p9M6A53U9tV1ffwgDsQ8Dg98cSzAF8cAfHEswBfHAHxxLMAXxwB8cSyY1Bd7emkD0Av6QsT/Lr0sGcTLEz3+xz7WnFCm+33wwQcDH4exfdAHBJhOmnzWfeqPf/zjpHYJP4b+7b44DQzUFw85ZOJW2su4PT4Okul+Ad127NMxjgPfPQMv2WFmGKgvcn38iRn+n1ID4+Mf/3hERPzhD39o/Zmux1Mfnx6zC/H0w+OP5Bp1mOev7Th0W9s1EsxqJvVFXtrAtFF6GTOTi4lSgNTvHqVFDcBM0OQfg3jR6n45yguZfl4yjXK8GebYR/m8wfTD9fEnRvVc9PKy5gBd/62l8RFPp0ZXfkNX5xjGB2raAAAAAAAAAAB0EF7aAAAAAAAAAAB0EF7aAAAAAAAAAAB0EGrawIzRtjhw07ZSYeMDhesOcOihhyZba2W8//772X5aiwLNKcx2Sj52oNiu2xF5DQKvR9C2Vg31pQAAAAAADoZMGwAAAAAAAACADsJLGwAAAAAAAACADoI8CgaKSptcsvRnf/ZnyVZ5xWGHHZbtd/jhh096DP28f27OnDmN43jrrbeSvX///mw/3fbb3/4229Yk+UC6AaNGSfbk2xT1U93PfVbliH48lSSqVOr3v/99tl9JYqU+N8qtwQEAAGBwlNY3/ezXC/3IumkNDv1Cpg0AAAAAAAAAQAfhpQ0AAAAAAAAAQAfhpQ0AAAAAAAAAQAcZyZo2Wq+krf6vpGX0Y0ynprCXYx8YY9c0jm1bbX/iE59o3FaqR6OfO/roo5O9ePHibL958+ZNeryIiDfffDPZ27dvT/bLL78cTXirca1xU6qp0bX56Tp+zZx44onJPv/887NtOv9PPfVUsl955ZVsv3fffTfZzMcEbevWKN7Ke+7cucletGhRsn2eli1blmz3xb179yZ706ZNyd68eXO23549e5L9m9/8Jtv2wQcfJLsUu8eB0ly11eT7eennnHk8bKJffT66/sHgtd6WL1+e7LPOOivb9vrrrydb46neLyNyf2MuJqffOmGKntte/L6fOWkbE2ZyPTwTlM6rx7iZjKdNnyOeTk7J33xNqedanzvUjsjrZ+ra58gjj8z20+P/7ne/y7a99957k9pes0//LtXs09hb2m820Y+/9RJP+xlH222DnkMybQAAAAAAAAAAOggvbQAAAAAAAAAAOkhn5VGeatTUerYkVSmlzyl+DP17EC3clF7SXLuUCteU+utyCpU2leRRmtLt6d1NkqhVq1Zl+y1cuDDZPocvvfRSslXmpOmLEXmqo6YlRjSnDJdaFcNH49fMySefnOyvfvWr2bbjjz8+2do6eufOndM0uvGhFD+aYuMRRxyR7bd69epkf+UrX0n2ihUrsv30c/696nMbN25M9n333Zftd9dddyXb57cpfXiUaUqn9TR6/dulZx47D1CSOJTilX6XH7spRdmPp/PjcVm3aRyljXv/eMr/Oeeck+yvfe1r2TaVlW7bti3ZLo/q0tpjmPSSDq9xtMmOyOdLz7P7vX7O56Otv7SVZOi2UZVktI2nel59jarxVT9XkuboXPh+egwfh35O7ZKsxudd50rXsqMcT5vmsSSB8ntVU4kFfWaIyGPlkiVLkq1r0oj8unjnnXeybbt27Ur2jh07kr179+5sP13T7Nu3L9um8n49vj+v6HyPil/2S9MzZ1tZqj9n9CNt8muuVCajaT8/dkl63EYGRqYNAAAAAAAAAEAH4aUNAAAAAAAAAEAHmRF5VFMXil7SwL2a9wE8fUlTBEupUvpdno7YlGbo+zWlevvnxi2NrW2aWUmSpvPh6d0619pZ6Ljjjsv2++QnP5nst956K9um8+HV3tuOQ+ewJClomzI3LvRTeV0/4ynJZ5999qR2RH7edb7HzadmGp0PPa8rV67M9lNJ1Jo1a5LtHd80PbmU3q37eXzQLlPuz6WOCkqXr4u2qfOe6q33Qr8PqnzwmGOOSbZLyFQiqvGw1CHKt+m4NFbu378/209Tun0eNQ28NI/jfP90ptoZw31RpYtLly7Ntunc6HXVbzeNcaHJD0rnpSQNV0mGduCLiDj22GOTfdRRR036eT9+qWONyim0O1hE7n9vv/12tq1pnVvqctSUzj8MHy3J00rPEtoxyOdm/vz5ydbupKWyBhrH/Lv0HGsM9jFqvHZpsM6hxk//W+fQ4/+oxlM9R75e0PuRx0Cd1/POOy/ZF110UbafdsHU+fbjqS/6udX7n8qjvFPts88+m+wXX3wx26adM9V21O+b7p9dmN+pPiP43zr3pfWR+rZL/ZvWL/53aa411rpMTudGu5/6PE21+ymZNgAAAAAAAAAAHYSXNgAAAAAAAAAAHYSXNgAAAAAAAAAAHWRaatqUtGmqK1Ntb0Res0RbPUfkLdj0GKrjj8h1o6oR9jGpzqxUy0Q1wtquNiJvK/3aa681jmNU9aRKk67ZdaZ6nl0PWNIKKqoH1zZ8qv+OyDXa2so0Iq+PoXOhbaN9HD4m3Vevl9lQt0Yp+bNS0sLr3Ov8RkRcfPHFydYaHRG5Rlg1wT6P0FtLQ9UBa6z94he/mO13ySWXJFv9z1tRqi+61lfnXv3IY/zll1+ebG1HHJFr99vWt+kaPgd6XtRWXXZEfl8888wzs23aslQ/5/UrVHevsbGEa8fVN/We6Rp8vS+6n+o8lq7XUb1PTpW2tQD0evG6HBdccEGyvQaS1sfQeSvdj2cbOgeluotaCywir7+3fPnyZJ9xxhnZfieddNKkx2hbey8i4o033ki21kB54YUXGo/hvthU/7EXhumnbeOp+4DWLtGaJhERq1atSnZpbtSPXn311WT7s0TpWtK6KVoDw68rndPSNVJqizwOuA/o/cnrl2hr77POOivZ6pf+OV23+POcfrfPjz5f6DaNBxERv/71r5Pt98ymFtGltfco3iPdB0r+ofPbVOc0ImLBggXJPuWUU5Lt90U9vp9XXTupX3p9Rn3O3Lx5c7Zt69atydZY2/b5KaLdnJJpAwAAAAAAAADQQXhpAwAAAAAAAADQQaZFHuVpTpqKr3Imlb5E5Knf2qYtIk8x1TR9b82mch1NafN0fk1RcomVHkPlUQ899FC23+23357sJ598MtumKeia0jiKKW1OKaWt1P66qSWhS6x0flUW52mumpa6a9eubJumD5ekG/q3t2TUedM0Of9d4zCnJfz3NaVy+nlpatfoshj1dZeGaGqwSmY8nX/c56CJtinRnlp8wgknJPuGG25I9rXXXpvtp5KYffv2JdtbVmraqPuRylT1eCr7icjbvZ977rmNx/dY3gXatL71WKk+obbf0/Q+edVVV2XbTj311GSrT6hEKSJPx9bY6D6r6eJ6jfg4NEa7JEClWN4O3GP9AWar/0Y0//ZSWrX6s0s8dJ7c79etW5dslXgg+Z08dpbaSrskQ1PzL7zwwmSfdtpp2X66lti9e3ey3Vf0+NqKOiKXDqjf65ooIp//ktRLGRVf9LnR36Mxyedp2bJlyb7sssuybeo7uv7z+51KIbS1s7f81vudSnYi8vIQurbV+2zEwTLVJkqt2UdlTp22Lb+9dIKed39uUFR+rzJDnwNdl7qEX+/XOkaXKL/55puT2r6vSohdnjOKcbq0RtX5dd9R/9B3A7421Pvfpz71qWT7OlRjo977InIpVVMploh8zarzFJFfS8qgfY9MGwAAAAAAAACADsJLGwAAAAAAAACADsJLGwAAAAAAAACADjIjNW2atKbeOk1bAXs7cNUU6udct6aaOa194Bo2rbPgum/Vt6keUlsFRuQ6Sq/F0aQ5Hhet6QG8tkhb/aLi14Fqw/U6cM339u3bk+0t9LSFomoPvaZN23bgpdbCoz6HU6Gko1b0WtA6HBF5C1S/nh555JFkay2O2XzOmyjVTHHN9zXXXJPsr3/968k+/fTTs/209eXatWuT/eCDD2b7qQZcY2tE7sNa38HHpHpkr2mm9cQ0DniMGdZ10eZ7fZ+mul5+L9FzsXr16myb3k+ff/75ZD/xxBPZfhs2bEi2nj+vR6N1bNQv/W+dK21lGpFr00t1llSfjz8fTOmc6LxddNFF2Tb1K79n6nXh9RJmM0112hw977pejchrpWjdBfexp59+OtmPPvposrV+YkTe2taPob6oNRm97ofWZSnVwyj5Yld9sxRP9Xz5uVu0aFGyzznnnGybPgts2rQp2XfddVe2n27TeiS+ltW1jtcI0+tH16G+1ixt03nTbaNY++Sj8N/UVONrsr8P4LVqtB7Rc889l2xda0aUa7Gqn+oYvW24Pq9oLauI/PlUn11K890l2raY9zWq+qavB7VV+9VXX51sr+GmPqe+6HWotD6m3/s0JmhNm9Jzvc+NxiPd5nFqqnNIpg0AAAAAAAAAQAfhpQ0AAAAAAAAAQAfpWR7V1Nq01AZa0bSkktzFU4801Um/21un6ef0+C6L0VTFiy++ONu2atWqZGs6lH9XqTWbUpIMdTX11GlKf/NUr9J50JRFbcPoLTE1VU1T7zdv3pztp22+XSanf2uKsMtvStvaprHpuSn5xajM9aDQ36tphu5vei241ELT+UsSNTjYRzVt1NPAb7zxxmRrC3aPk3fffXeyf/KTnyRbY3VE7jveYlUlppq+73JTHYemI/sxNY64zw6LNi2/Hb1PqqRswYIF2X46dy7JUH/ZsmVLsp999tlsv7179yZbZaAuHdBxuMytqV27t0BVPC7r/WG2xcNBov6h7aUj8jWLt4B+5ZVXpndgHaAfX2zC/UP9z9ctF1xwQbJVPuhp+ipV1G26FonIY6XHOZUSuKxb0c/58dUXuyZV7GcOm+QyOhcREUuXLk22tmuOyGUxGzduTLZKKyLyuFu6B+kzgkunNG6qrMOlPTpvpXjatTnsl6bnJZf+6f3Tz5lKdPVceDzUNs26zX2laf0Rkc+/HmPbtm3Zfi+99FKyXTql665SOY0Sg4x7g0Tn0OOpxjFd/0XkzwkaW91n9Tzr88JTTz2V7acStJI0X8+fP89qfPBrSY/f7xy2gUwbAAAAAAAAAIAOwksbAAAAAAAAAIAOMrDuUaWUIkXT+zxFTKtme2qZphvpMUqV7ktV17X6vneq0jQtTbPz1GJNkSylnrbtsNNlmn5DSbLi8iJNK9TU0BUrVmT7zZ8/P9naEcUrrmtasKcsqhxHZW2eyqp/+3ib5qqX7gqjOt+DQNNXNf1Qq8JH5D6mKaQREVu3bk32bD6XTZTSh1UCev3112fbmiSg3nXo5ptvTramm3pKvsYB91OVFGhqq18HGkM9BbbUIaULTDWdX6VI2r0gIu+m5+dF0/ZL3S90vvTe5JI6jYEeK/W36Tg81ViP6feHprRhfPuj0Xiq14Tavt/69euzbS4/na2Urjc9fy711zjk8Us77+n6Q2XcEfk9Tv3Uv0tjgndy0441KsHpRf49zr6o60GXlOq59G06Vzt37ky2PptENK97fQ713urSEP1b46kfQ+fQv7fUpWZUaboW/blS//bnr6ZyHX6/a7qP+fOEPhO6HFi/W2XILlHWa8u7GTd1eevCs0abtU3bcinuA/pccMYZZ2TbdI2qcmx/RnjggQeS/dhjjyVb5yIilydq/IzI11wq5/eSKNptzNe5GodLndymOk9k2gAAAAAAAAAAdBBe2gAAAAAAAAAAdBBe2gAAAAAAAAAAdJCea9q00WO5hqupHo2jbc9KWvuS/rapxbJqS32b10jQv1UDrnq2iFzD5r+rSdM2LrrTA5TOv+sXtXbQ+eefn+wzzzwz20/nSnWrrvWdO3dusl2DqppRnSffr3QtNW0btzmcLnT+Ve+/bNmybD/1+zvuuKNxG0zQVMdG6yhE5Of8iiuuyLapbldbF950003Zfg8//HCy1ac8xje1Ho3I47/WKvMaYTpej9faclN/s98nhkWbmFCKlfp7vUVtUzvKiIj33nsv2do21vX/Te1wtZ5URF7jwXXfTa3bPaaW6uKM871wutG5WrlyZbL1PhiRr1luu+22bFupPfGgaVqLTTeD/C6/tvVcL1myJNum9W60Vs2ePXuy/dRPdazeEnrhwoWN36Xj0Jjq98tSPZRR98XSmDU++b1E45gfQ8+Jrjc9Tvq99gBeI0frn3hdIh1HaZ2rv8Xvrf73OKBzUrqX6N+lWkJ6nkutntXH/JrRefXv2rx5c7K1DtK+ffuy/fQ5xGvwlGqgDJt+YkPTZ7ROV0S+xvDnAo2nuvb0WkEbN25Mdqlmm9Z49Dqqn/70p5Ota02tGRiR19j0+W2KtYOeTzJtAAAAAAAAAAA6CC9tAAAAAAAAAAA6yMBafpdoSnHT1O6IcjptU7qVp6+qJEPT2DzdTdMWPS1L01Sb2jNGRLz++uvJdnnUqKeeltDf4/KEUkqptm1TSZSnjWp7RT2Gfj4in1P/rqZWmjpnvl9Juge9oymlms7v86gpiPfcc0+2bSbT+UeFJlmNpnVG5C0UFyxY0HiMLVu2JPvxxx/P9muS3HhMK7Ue1c9p+r63vdQxqZQy4uC02sk+M0z6kUfpOdP7mP9WvR95erfexzTV2KVnel/Ua8alNZoi7vKoefPmTToOH6/Od1NrXOidpnbTLqvZtGlTstetW5dtG7e1yKBoWtN4fFHf8fPua5Cmf9c0fZ1T/feIXELubd011usaRuN1RL4O9d/Sldg5Gf3E06Y1t68hdD3o90yNcRoLvX2wfk6vA/18RC759XWPt44+gLahjhiezLALlK5fndf333+/cZve+3x+1P9KsmuVNvm1oOgzhD/flu6L4zyv6m/+vK6+48/oei51regSKPWX+fPnJ9vXJSqBWrNmTbZNW7rr2slLouzYsSPZPr+lNfAgIdMGAAAAAAAAAKCD8NIGAAAAAAAAAKCDzIg8StG0tV5Sp9umr2oqVikNUlMfXR6l37V79+5kq1QqImL//v3J9mrg45zupue8VOne04I1NVFtr66t51XlFN7lS9PpvJq//q0SAE+V1e9SWdZk42pinOe6F9wXVeJy2WWXJdu7imk1eE0/hI9Gz7l3rli0aFGy3RfffPPNZD/33HOT/nvpu7w7USmNuSkmuLxA01w1HTki93W1Pf6MUip52/NSSrtVScVVV12VbJc9qSxU/dJT8VUSde6552bbtNNGk0QvIk9L9nRo/c0ai7s+V8PA/UjlFRdccEGy/b64fv36ZOv9baYZpTltWtP4vapJfh+Rz4PKLlTmFJH7nB7DpY8qgfPYrjFBY7H7m/qiS0ia5BqjMm+ltb/Ohc+TSshcEq+x8corr0y2zmdExGuvvZZsjYvaqSgiX+cuXbo026af07nx2K1z6L6uv22cSzJMhv5Gl6ro/U67Y7rsWp8T9L7r57kkX9Y51+fMUsficacpnvp51edmL12hzwIan9zHtNSGHs/jqcqj3Bd1flUepZ3BfIz+zN/0m9uWemkLmTYAAAAAAAAAAB2ElzYAAAAAAAAAAB2ElzYAAAAAAAAAAB1kxmvaqJ6rF21XU02bUm0F1R56u71LLrkk2QsXLsy2PfPMM8nWehv79u3L9tO6C16fp209lFGhqY5QqY2k15lRXbZqw72VutYR2rNnT7K9RbDqR31+VUus2/y7nn766UnHFJHXXCjphWlrO4HrVbWVu9fHULTNtM8xHEzbul2qw/drVnX9qs93/+in7oHXVdB6LTomb0Ou8cJrDeg41B7lOKuxUvXR3q5ba6m5Tl7P59lnn51sb22qtYr0e73Gl94zvY5DUy0OH5MfUxnl+ZppvBaHtn32OnzKY489lmyvYwKT07YegdbY07gZkbeiVT/y9aXWZNBY5n6kNRl8m9bf03Wox031N1/flFocjyL6G/Re5S2Ct2zZkmxtERyR1/RSe+XKldl+ev/U+52fx6bW4P63fpfXtNHj+xprHOatROlZQ69tr2mzc+fOZOv59LW6Xhvq914DUP3P6+Jo7Sl9XtFnRz9+v/M2inVxSs/r+kzt50vnRteGPoc69zpvWjMqIuLUU09Nttfy09be69atS/aLL76Y7afrY1/nND0jDnrOyLQBAAAAAAAAAOggvLQBAAAAAAAAAOggMy6P6pemdDJPt25KcVuxYkW23+rVq5Pt6fzbt29PtrbDdelA2xSoUUxpc9q2cCu1/NbzrOm9ntqocoBt27Yl2+Vpml66fPnybNvixYuTrW1xPaVZU5U9fbhJGuLo/Pr1OEotiKeKXwvnnXdesjW91OfgkUceSXZJWgET6DWlPuVtYUtyo7179yZb/c3bGOqc6rXt0g3FW2Kqn6ovqo/6+Hft2pVtU99Xv3SfGiV/05ii6fY6HxERDz74YLJd7nL88ccnW33H50djsV4LLkfUuOxp+nptqD/7MdS/9XdFjI+0bSbweKryN93m8g+V/HKOe0fjht/3NQ6prDciv7ZV7uJz0OT3vl7ylrWKSqJUkuFrVPX1UsvvUbxOPL7rb9BY5efkySefTLbLJBYtWpTskoxU46SeRz/Heg/25wyVb+ja068D/W4/vm7r+v2uLW1LMeh8+/pG/VQlLn4/2rp166TH87nStcrVV1+dbVPZjconH3rooWw/Lfvgv2Vc5u4A+vtK86SxSyXcEQevI5vQ/VQWrs8fEXmZDB/HE088kWx9HtE58895TNC4Pp3xlEwbAAAAAAAAAIAOwksbAAAAAAAAAIAOwksbAAAAAAAAAIAOMiM1bZradU8HenzV+3/+85/P9jv55JOTrTVsInJ9m7ZfVR1xRHNL6Ijx0yhqjQTVe3odGNXj+jatg6DHcH3h/v37k63aVK+Fou0UXV+otTNUt+z1c1SP7DpW/7sJ6rBM4BrUz372s5NuU015RN6Cc9z8Zrop1ZDSv0uta1999dVkl7S4eoxealmpL65ZsybZ3gZeY4y2XYzIa4uprt9/V5evHx+bxg2tu+BtJvW8uMZa6yKU2mLqd2sM1NpGvtHL8iIAAA+ZSURBVJ/XgtA20zqnfs1o3QCvwTCKtTOGhcfTa6+9Ntl6b92wYUO2n69n4KPR675UQ0TrB+k6MSJfK6pfeqxUdO2jdXAiIhYsWJBsb/mta9Hnn38+2RrLI/LaKx4Txq0eiv4+/d1eC1HPl689jznmmGTrutFrhOmc6hrSv0ufR7xtuNbY0Fo6+u8R+Tq0bZvhcaGplqb/7b9d/VZrpZRq4Ol9y6+L119/PdmXXXZZtk3vhaeddlqy9fkzIr9mxr1Ve1M89ecvnSevjdeEXwda+2vJkiXJdn/T50VfX956663J3rhxY7J9DVSqAzZTaxsybQAAAAAAAAAAOggvbQAAAAAAAAAAOsiMt/wehFSq1AZOU4ovv/zyZF944YWN43jqqaeybSrf0JZk3g53HNMRD+ApaE2SKG3nG5GnoHl6t6b46jH8POrn9Pj+XSeddFKyPRVO0+RUbqV2RJ7u5teS/mZNbfTx+nUxm9DrRFN8I/I27HqeNT05Ik89nW0cuOZ6iSW6r55XT+lV3J81lVz9stTKW33ApYOaSq6+FxHxhS98Idmf+9znkq2xIiKXBWmb64g8TVXTUEdJllpq86kxxGWgKmVz31FJlM6jyyn0u/R4nv6rc+LtcEuyNEVToF2SAWX0GjnllFOybSpP0/PqLeLbppnD5GhM0fgakZ9bT/VXaZL6n6+DNI62XQd5vFXJx44dO5Ktvu3j73Js7IfS84NKMvycvPzyy8l2OZOe86Z1qKPXhK9lSp+75pprkq33XZfV6DjGUV7q86j+oefF72nqE6XSBk3tpyOaZeLeGlyP52UyVA5+7LHHJvvoo49uPEaJts/Fo+LPpXiqlH63bvPrQM/zDTfckOzTTz8920/XOjfffHO2be3atclWCWwX15dk2gAAAAAAAAAAdBBe2gAAAAAAAAAAdJAZl0cpg0g18sr8mlp44403JlurwkdE7Ny5M9m/+MUvsm0vvPBCsjVtvQupUTNFSR6l6Wme/llKKdXPabqbphRGRJx11lnJ1tRD7+Sg3WeuuOKKbJt+t3bX0C40EXmasafyN1Wn76UjyrhfM3pdaLeoiNwXNS3y/vvvz/abzfKyfq4P/Yxesy6L0DRev0ZV+qJppC7N0W5FOoceT88444xkf+lLX8q2XXrppclWX3ep4i233JLsxx57LNvWJLkZJf/ysTbJvDydX+fRz5mi8cpTjfXvUtcYPc8uHdDP6fH8GEii+kfnULtFReQdifR6eeCBB7L9Sino8NE0yU8jch/w+5b6aVO3zYhmefnixYuz/TRW+jpXJXEq4ffuQqMUH6dK031RO0lF5DJil8FoXGuSx/vfGjP9/Ot3u4xx165dyda1rMuGtTuOj6NJUjJK816SR+kcqBQ4In82cAnikUcemWw9f74O0rW8zpXvp88uvvZp6pTkx2gr/ykxKvOq4xzEmPU6cP+4/vrrk61SfI+799xzT7J/9rOfZdtUEtX19QuZNgAAAAAAAAAAHYSXNgAAAAAAAAAAHYSXNgAAAAAAAAAAHWSoNW0GgeqDI/L6CaoTdV3dunXrkn3fffdl27SmwKhoCAeNayyb6ru4hlf1qKo59WPqMbR1d0TeKvq6666b9Nh+fNePbtq0Kdl33313srdu3ZrtpzVtSrUAVOc4m3XjjuqF16xZk23T+VHdvc5NRPc1pF2jyf+8Foq2H/VrVuslrFixItnus9oGU2Ot1p2KyOPu0qVLs23qt9u2bUv2rbfemu3305/+dNLv9fGPi781/Y5SjSyfR6WtZl6/1z+jGn+vE6D3AN1PY6gfs+19ZFzmdKroOb/yyiuzbVpXQWtNeTwdx7bA003b6690zTa1Fvb5aJofj71z585Ntsd2nXOtxTGb/Kjtb/X1RdsWxBqrvMZj6fiKXhNaSycin1ONp359aN0jr9Oh4xrV2op+bnW9oLa3etbaMt4mXet/aX0b9yM976V732c+85lkn3jiidk2rWn04osvJtvbv+v89Htf7PI8tqGX8Te1+V65cmW237e//e1k67p28+bN2X7f+973kq3PIxGj9QxCpg0AAAAAAAAAQAfhpQ0AAAAAAAAAQAcZSXmUpk0dd9xx2bYvf/nLydaUOU9V+/GPf5zsUU6Vmi481bIpLd/bX2sKqG/TtmraWnjBggXZfieccEKyNQXSx6QtE9evX59tu+2225K9du3aZPtca7pkad5LkrBRT1nsFfW/+fPnJ9slMzpf27dvn9T2/aA39Jp1SdHTTz+dbJVAReTzduGFFyZbpYkRedquphkfffTR2X7ahtFTzlWSeNNNNyXb2y6qdMpjx2zysX5/az8SjxIuR9W4p3HeJcqaWu7p/Hpt4PcHo36l8u6I/Hzpfezll19u3A+mRi++2LSv/3uTTGLevHnZfiqX8tbU2j66JJmcTTSdf5eitJVltvWjkty0tG7UlvF6Hy+VAXDZjsZhPcYo3S/bygddHqUSKJdk698aU739+7vvvptsnZ/Fixdn+6kkR9dBEREvvPBCsu+8885ke4t3ne8SOnfjFstLklJH/UCfEb/1rW9l+51yyinJVqn2D3/4w2y/J598Mtmj/IxPpg0AAAAAAAAAQAfhpQ0AAAAAAAAAQAfhpQ0AAAAAAAAAQAcZyZo2qm285JJLsm2rVq2a9DPPPfdc9rfWe0ATfDBta9p4G0PVXu/cuTPbpppO1ZZ6LY4lS5YkWzW8vt/jjz+e7Oeffz7bpnU0VOeo7fkicm2j/+YmveUo6yEHgdY5Oe+88xr303pBDz/8cLL3798/PQObJaguWK9F1WdHRDzyyCPJXrRoUbZN27NrXTBvZ6l+r9r6t956K9tP60tt3Lgx2/bLX/4y2ffcc0+yvRZHqf3qbKJUF6FfmuoueLtVbzusvPHGG8nWWjU+Xq1D5vVu9HpqakM+29DzsHDhwmT7/Ujvmc8880yyvV4fdItS215d33htP0V9LyKP++rDpRoR4+5jTb99EPG0VIujbTw96qijsm26r66bfY2qzzseT5vmfpTmut+21noutL5NRMSpp56a7GXLliXbawIdfvjhydb58Vps+uyibb0jIu66665k6zpXa3hG5PG8bW2XUZrHqeK1nHQdcd111yV79erV2X66brz33nuTfcstt2T7eZ3EUYVMGwAAAAAAAACADsJLGwAAAAAAAACADjIy8ihNA5w7d26yXR517LHHJlvTie++++5sv7179yZ73NqqDQJPy9O09iZ5hv/tco3du3cnW+VL999/f7aftg/WVFFPG1X5jae+NbVTHLTUYDaivqjnWX0qIpfO3X777ZN+BnqnqSWk+4Cm8Xp7bZ0rjaEnnXRS4/dqPN2wYUO2TeUaakfkLTE1zX+2ywzbpvMr/caephR+b6Oq7Uw91V/bTCvejljTnD3NXI852+d/MvQ+u23btmybykpVcuj3RRgc7ouDkKCof6gEYM6cOdl+Gm917RSR31tL8QJ6m8O2bcM1jqnt8iVtN612RO63Kv13uaPOtcdTl5SMIn7O9b6gtq73I/Lz5P6hsVLPs0rBI/L7nc6xl3bYvHlzslXiHRHx4IMPJlvbfHvpiJL8uySdGifcj/T6demaStwuv/zyZLsP6H3yBz/4QbJ37NiR7Tcu6w0ybQAAAAAAAAAAOggvbQAAAAAAAAAAOkin5FFNFdkj8rTDk08+Odnz5s3L9tP0+1deeSXZv/rVr7L9kGj0Rtv0vbYdYLSjk6Nz31a61m8FeugdTeH/+c9/nmyXxWja8JYtW5LN3AwOPZfe4U19zOVMmjp65513Jtu7MKh8RlOOXQqnUkhN64/IZVvMfe+U7osaH0syCU0p1pRkl0fpMTzlfO3atcleunRpsr0LmKax+zXJ/B+MnpN169Yl+5vf/Ga2n0pp1H/HJe17mLSVKvbjiy4z1LWs+qXHVL1nqsQ0ImLfvn2txoS/HXwOSt22mtabvl9TPHV5lOJdM7W7o94jXVajnRn93trU1XWUrwONZ3ou/NlCn+FcoquSGe3Id8IJJzR+l86PnvOI/FnS5Wv63TpGv5Z0DkrPK6M0V73isVDXHy5dO/fcc5OtZU90LiLy0guPPvpossf1GZ9MGwAAAAAAAACADsJLGwAAAAAAAACADsJLGwAAAAAAAACADjLUmjYlvbBr37Qd2Iknnti4n7YlVc2otmKLoM33VChpLsdZjwkT6ByrxvrZZ59t3K9Jew3Th55/bweuLUa1PkJJ/1+qa4XfT43pjqlNc+f3QdX4e40qvU7Wr1+f7Ndeey3bT2vhuK5cj881czB6fvy86vmnjs1gaXst9uOn/u/qExqH77333mw/rVvk9aV0W9s6GuNO29/aNgaVaivqOVfb77Pabtrrrujca0tpP4Y+03jb69Lcjyo6JzpX/vu0Zp/XyNQaUP6M2PRdbX17EGuf2eSXpVp7JTRO6rOF19C74447kq11icbFHxwybQAAAAAAAAAAOggvbQAAAAAAAAAAOkjVS5pWVVUDzenytClNY9M2ehERRxxxRLKXLVuW7EsvvTTbT1vxPfzww8n2VO9Ra0ta13V/OWbGoOcQeuKJuq4/PYgDdWUe27ZAHSfwxbFg6L6o/jLoe04pJbntNr8HH3bYYcnW1rYu1dH0fpdHDTomjLMvjnLb3h4Zui8Wjpf93XYOSvdF/VvXq94uWv3P2x3rmlXtYcpWZ5MvDuIYOvdqOxpf/TqYhjVWZ30R2tMlXyyVPdHrfs6cOdm2448/PtmHH354st94441sP5UNqxxxDKSik/oimTYAAAAAAAAAAB2ElzYAAAAAAAAAAB2ElzYAAAAAAAAAAB1kqC2/nVJLWW3ppu1GN2zYkO2n+rl+WyFOZ60BgHFlXGvYAHwUB+4Zbe8r042Po+09rbRN9eJat6Z0b+X+2T+cu+EziDlw/1Bf1JpPXq+k6TM+rnH0tzbxtOkzvX6uDf3G0xJai8jrgjV997jML8we9Jr1WKjxz2vL6jO/+ttsX2+QaQMAAAAAAAAA0EF4aQMAAAAAAAAA0EF6lUfti4jtg/ryftO0S6mEY8qiAR5roHMIPTF28zgb0hGNsZvDWcpA57Gu64+cx2H6Sj/fPQL3WXxxPBi7eexnbTvi99IZj6fODLc3n/JnOjrfY+eLs5DOziHP9T0x6TxWHQ0cAAAAAAAAAACzGuRRAAAAAAAAAAAdhJc2AAAAAAAAAAAdhJc2AAAAAAAAAAAdhJc2AAAAAAAAAAAdhJc2AAAAAAAAAAAdhJc2AAAAAAAAAAAdhJc2AAAAAAAAAAAdhJc2AAAAAAAAAAAdhJc2AAAAAAAAAAAd5P8Du0qmBm4wZdAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dae_predict = DAE_V1.model.predict(x_test_noisy)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(np.reshape(dae_predict[i], (28, 28)))\n",
    "    plt.title(y_test[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoising_Autoencoder_V2():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , encoder_conv_filters\n",
    "        , encoder_conv_kernel_size\n",
    "        , encoder_conv_strides\n",
    "        , decoder_conv_t_filters\n",
    "        , decoder_conv_t_kernel_size\n",
    "        , decoder_conv_t_strides\n",
    "        , z_dim\n",
    "        , use_batch_norm = False\n",
    "        , use_dropout = False\n",
    "        ):\n",
    "\n",
    "        self.name = 'autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "\n",
    "        ### THE ENCODER\n",
    "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
    "\n",
    "        x = encoder_input\n",
    "\n",
    "        for i in range(self.n_layers_encoder):\n",
    "            conv_layer = Conv2D(\n",
    "                filters = self.encoder_conv_filters[i]\n",
    "                , kernel_size = self.encoder_conv_kernel_size[i]\n",
    "                , strides = self.encoder_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'encoder_conv_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_layer(x)\n",
    "\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate = 0.25)(x)\n",
    "\n",
    "        encoder_output= Conv2D(\n",
    "                filters = self.z_dim\n",
    "                , kernel_size = 1\n",
    "                , strides = 1\n",
    "                , padding = 'same'\n",
    "                , name = 'encoder_conv_' + str(i + 1)\n",
    "                )\n",
    "        \n",
    "        x = encoder_output(x)\n",
    "        \n",
    "        self.encoder = Model(encoder_input, x)\n",
    "\n",
    "        ### THE DECODER\n",
    "\n",
    "        for i in range(self.n_layers_decoder):\n",
    "            conv_t_layer = Conv2DTranspose(\n",
    "                filters = self.decoder_conv_t_filters[i]\n",
    "                , kernel_size = self.decoder_conv_t_kernel_size[i]\n",
    "                , strides = self.decoder_conv_t_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'decoder_conv_t_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_t_layer(x)\n",
    "\n",
    "            if i < self.n_layers_decoder - 1:\n",
    "                x = LeakyReLU()(x)\n",
    "                \n",
    "                if self.use_batch_norm:\n",
    "                    x = BatchNormalization()(x)\n",
    "                \n",
    "                if self.use_dropout:\n",
    "                    x = Dropout(rate = 0.25)(x)\n",
    "            else:\n",
    "                x = Activation('sigmoid')(x)\n",
    "\n",
    "        decoder_output = x\n",
    "\n",
    "        ### THE FULL AUTOENCODER\n",
    "        model_input = encoder_input\n",
    "\n",
    "        self.model = Model(model_input, decoder_output)\n",
    "        \n",
    "    def compile(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "        self.model.compile(optimizer=optimizer, loss = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")) \n",
    "\n",
    "    def train(self, x_train, y_train, batch_size, epochs, verbose = 1):\n",
    "        self.model.fit(     \n",
    "        x_train\n",
    "        , y_train\n",
    "        , batch_size = batch_size\n",
    "        , shuffle = True\n",
    "        , epochs = epochs\n",
    "        , verbose = verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "error",
     "timestamp": 1627298373631,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "pExd_D7OfJdz",
    "outputId": "15692fa1-9859-4efe-fde6-e47c52f3e739"
   },
   "outputs": [],
   "source": [
    "DAE_V2 = Denoising_Autoencoder_V2(\n",
    "    input_dim = (28,28,1)\n",
    "    , encoder_conv_filters = [32,64,128,256]\n",
    "    , encoder_conv_kernel_size = [3,3,3,3]\n",
    "    , encoder_conv_strides = [1,2,2,1]\n",
    "    , decoder_conv_t_filters = [128,64,32,1]\n",
    "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "    , decoder_conv_t_strides = [1,2,2,1]\n",
    "    , z_dim = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_102 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_103 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_104 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_105 (LeakyReLU)  (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_4 (Conv2D)      (None, 7, 7, 512)         131584    \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 128)         589952    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_106 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_107 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_108 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,201,921\n",
      "Trainable params: 1,201,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DAE_V2.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1627296413955,
     "user": {
      "displayName": "김찬준",
      "photoUrl": "",
      "userId": "01130487808933653943"
     },
     "user_tz": -540
    },
    "id": "XS04oM8lnF6s"
   },
   "outputs": [],
   "source": [
    "DAE_V2.compile(0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1dP9udTdOnr"
   },
   "source": [
    "- #### **결론 :**\n",
    "    - **오토인코더를 왜 쓰는가?**\n",
    "        - 인코더를 거치면 일종의 차원축소처럼 보이게되는데 이 때 확실한 영역을 구분하게 된다면, 그 주변의 좌표들을 통하여 비슷한 이미지를 생성하는데 기여할 수 있습니다.\n",
    "    - **오터인코더의 한계?**\n",
    "        - 모든 데이터가 인코더를 거치며 정확히 구분되지 않을 뿐 아니라 잠재 공간 모두에 분포하지 않습니다. 즉, 잠재공간이 존재하지만 엉뚱한 곳을 찍었을 때는 전혀 다른 데이터를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFxcbBrNmv4f"
   },
   "source": [
    "---\n",
    "\n",
    "code : https://github.com/Chanjun-kim/Chanjun-kim.github.io/blob/main/_ipynb/2021-07-25-AE1_AutoEncoder.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvWAWUs7mv4e"
   },
   "source": [
    "> 참고자료 : [https://www.tensorflow.org/tutorials/generative/autoencoder?hl=ko](https://www.tensorflow.org/tutorials/generative/autoencoder?hl=ko)<br>\n",
    "> 참고자료 : [https://github.com/davidADSP/GDL_code](https://github.com/davidADSP/GDL_code)<br>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ZCQ4MIS2mv4N",
    "6vsMVZXjmv4R"
   ],
   "name": "2021-07-25-AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
